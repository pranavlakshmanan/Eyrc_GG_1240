{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************************************************\n",
    "*\n",
    "*        \t\t===============================================\n",
    "*           \t\tGeoGuide(GG) Theme (eYRC 2023-24)\n",
    "*        \t\t===============================================\n",
    "*\n",
    "*  This script is to implement Task 1A of GeoGuide(GG) Theme (eYRC 2023-24).\n",
    "*  \n",
    "*  This software is made available on an \"AS IS WHERE IS BASIS\".\n",
    "*  Licensee/end user indemnifies and will keep e-Yantra indemnified from\n",
    "*  any and all claim(s) that emanate from the use of the Software or \n",
    "*  breach of the terms of this agreement.\n",
    "*****************************************************************************************\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### IMPORT MODULES #######################\n",
    "import pandas\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "###################### Additional Imports ####################\n",
    "\"\"\"\n",
    "You can import any additional modules that you require from \n",
    "torch, matplotlib or sklearn. \n",
    "You are NOT allowed to import any other libraries. It will \n",
    "cause errors while running the executable\n",
    "\"\"\"\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# ADD UTILITY FUNCTIONS HERE #################\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(task_1a_dataframe):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    This function will be used to load your csv dataset and preprocess it.\n",
    "    Preprocessing involves cleaning the dataset by removing unwanted features,\n",
    "    decision about what needs to be done with missing values etc. Note that\n",
    "    there are features in the csv file whose values are textual (eg: Industry,\n",
    "    Education Level etc)These features might be required for training the model\n",
    "    but can not be given directly as strings for training. Hence this function\n",
    "    should return encoded dataframe in which all the textual features are\n",
    "    numerically labeled.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    `task_1a_dataframe`: [Dataframe]\n",
    "                                              Pandas dataframe read from the provided dataset\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `encoded_dataframe` : [ Dataframe ]\n",
    "                                              Pandas dataframe that has all the features mapped to\n",
    "                                              numbers starting from zero\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    encoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
    "    \"\"\"\n",
    "\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    # raw_df = pandas.read_csv(task_1a_dataframe)\n",
    "    # Making Male as 1 and Female as 0\n",
    "    raw_df = task_1a_dataframe\n",
    "    Gender = {0: \"Female\", 1: \"Male\"}\n",
    "    raw_df[\"Gender\"].replace(Gender[0], 0, inplace=True)\n",
    "    raw_df[\"Gender\"].replace(Gender[1], 1, inplace=True)\n",
    "    # Converting EverBeched to boolean 0 or 1\n",
    "    EverBenched = {0: \"No\", 1: \"Yes\"}\n",
    "    raw_df[\"EverBenched\"].replace(EverBenched[0], 0, inplace=True)\n",
    "    raw_df[\"EverBenched\"].replace(EverBenched[1], 1, inplace=True)\n",
    "    # Converting 4 digit Year to 2 digit\n",
    "    raw_df[\"JoiningYear\"] = raw_df[\"JoiningYear\"] % 100\n",
    "    # Assigning Bangalore as 0, New Delhi as 1, Pune as 2\n",
    "    # City = {0: \"Bangalore\", 1: \"New Delhi\", 2: \"Pune\"}\n",
    "    # raw_df[\"City\"].replace(City[0], 0, inplace=True)\n",
    "    # raw_df[\"City\"].replace(City[1], 1, inplace=True)\n",
    "    # raw_df[\"City\"].replace(City[2], 2, inplace=True)\n",
    "    encoder = preprocessing.OneHotEncoder(dtype=int, sparse_output=False)\n",
    "    encoded_cities = pandas.DataFrame(\n",
    "        encoder.fit_transform(raw_df[[\"City\"]]),\n",
    "        columns=encoder.get_feature_names_out([\"City\"]),\n",
    "    )\n",
    "    # Assigning for Education\n",
    "    # Education = {0: \"Bachelors\", 1: \"Masters\", 2: \"PHD\"}\n",
    "    # raw_df[\"Education\"].replace(Education[0], 0, inplace=True)\n",
    "    # raw_df[\"Education\"].replace(Education[1], 1, inplace=True)\n",
    "    # raw_df[\"Education\"].replace(Education[2], 2, inplace=True)\n",
    "    encoded_edu = pandas.DataFrame(\n",
    "        encoder.fit_transform(raw_df[[\"Education\"]]),\n",
    "        columns=encoder.get_feature_names_out([\"Education\"]),\n",
    "    )\n",
    "    raw_df.drop([\"City\", \"Education\"], axis=1, inplace=True)\n",
    "    raw_df = pandas.concat((raw_df, encoded_cities, encoded_edu), axis=1)\n",
    "    encoded_dataframe = raw_df\n",
    "    ##########################################################\n",
    "\n",
    "    return encoded_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe_path = (\n",
    "#     \"/mnt/Storage Drive/Projects/E-YRC/EYRC_2023/Task 1/Task_1A/task_1a_dataset.csv\"\n",
    "# )\n",
    "# data_preprocessing(dataframe_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features_and_targets(encoded_dataframe):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    The purpose of this function is to define the features and\n",
    "    the required target labels. The function returns a python list\n",
    "    in which the first item is the selected features and second\n",
    "    item is the target label\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    `encoded_dataframe` : [ Dataframe ]\n",
    "                                            Pandas dataframe that has all the features mapped to\n",
    "                                            numbers starting from zero\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `features_and_targets` : [ list ]\n",
    "                                                    python list in which the first item is the\n",
    "                                                    selected features and second item is the target label\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    features_and_targets = identify_features_and_targets(encoded_dataframe)\n",
    "    \"\"\"\n",
    "\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    features_and_targets = []\n",
    "    target = encoded_dataframe[\"LeaveOrNot\"]\n",
    "    unselected_features = [\"LeaveOrNot\"]\n",
    "    features = encoded_dataframe.copy()\n",
    "    features.drop(unselected_features, axis=1, inplace=True)\n",
    "    # for i in range(0, len(encoded_dataframe)):\n",
    "    #     rows = []\n",
    "    #     rows.append(list(features.iloc[i].values))\n",
    "    #     rows.append(target.iloc[i])\n",
    "    #     features_and_targets.append(rows)\n",
    "    features_and_targets = [features.values, target.values]\n",
    "    ##########################################################\n",
    "    return features_and_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify_features_and_targets(data_preprocessing(dataframe_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_as_tensors(features_and_targets):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    This function aims at loading your data (both training and validation)\n",
    "    as PyTorch tensors. Here you will have to split the dataset for training\n",
    "    and validation, and then load them as as tensors.\n",
    "    Training of the model requires iterating over the training tensors.\n",
    "    Hence the training tensors need to be converted to iterable dataset\n",
    "    object.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    `features_and targets` : [ list ]\n",
    "                                                    python list in which the first item is the\n",
    "                                                    selected features and second item is the target label\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `tensors_and_iterable_training_data` : [ list ]\n",
    "                                                                                    Items:\n",
    "                                                                                    [0]: X_train_tensor: Training features loaded into Pytorch array\n",
    "                                                                                    [1]: X_test_tensor: Feature tensors in validation data\n",
    "                                                                                    [2]: y_train_tensor: Training labels as Pytorch tensor\n",
    "                                                                                    [3]: y_test_tensor: Target labels as tensor in validation data\n",
    "                                                                                    [4]: Iterable dataset object and iterating over it in\n",
    "                                                                                             batches, which are then fed into the model for processing\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    tensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
    "    \"\"\"\n",
    "\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    tensors_and_iterable_training_data = []\n",
    "    x = features_and_targets[0]\n",
    "    y = features_and_targets[1]\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "        x, y, test_size=0.3, random_state=1240\n",
    "    )\n",
    "    X_train_tensor = torch.Tensor(x_train)\n",
    "    X_test_tensor = torch.Tensor(x_test)\n",
    "    Y_train_tensor = torch.LongTensor(y_train)\n",
    "    Y_test_tensor = torch.LongTensor(y_test)\n",
    "    # Iterable_dataset = Tenso\n",
    "    tensors_and_iterable_training_data = [\n",
    "        X_train_tensor,\n",
    "        X_test_tensor,\n",
    "        Y_train_tensor,\n",
    "        Y_test_tensor,\n",
    "    ]\n",
    "    ##########################################################\n",
    "\n",
    "    return tensors_and_iterable_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_as_tensors(identify_features_and_targets(\n",
    "#     data_preprocessing(dataframe_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Salary_Predictor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    The architecture and behavior of your neural network model will be\n",
    "    defined within this class that inherits from nn.Module. Here you\n",
    "    also need to specify how the input data is processed through the layers.\n",
    "    It defines the sequence of operations that transform the input data into\n",
    "    the predicted output. When an instance of this class is created and data\n",
    "    is passed through it, the `forward` method is automatically called, and\n",
    "    the output is the prediction of the model based on the input data.\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `predicted_output` : Predicted output for the given input data\n",
    "    \"\"\"\n",
    "\n",
    "    neurons = 60\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features=12,\n",
    "        layer1_neurons=neurons,\n",
    "        layer2_neurons=neurons,\n",
    "        out_features=2,\n",
    "    ):  # layer3_neurons=neurons, layer4_neurons=neurons,\n",
    "        super(Salary_Predictor, self).__init__()\n",
    "        \"\"\"\n",
    "\t\tDefine the type and number of layers\n",
    "\t\t\"\"\"\n",
    "        #######\tADD YOUR CODE HERE\t#######\n",
    "        # in_features = 12\n",
    "        # layer1_neurons = 15\n",
    "        # layer2_neurons = 15\n",
    "        # out_features = 2\n",
    "        self.layer1 = torch.nn.Linear(in_features, layer1_neurons)\n",
    "        self.layer2 = torch.nn.Linear(layer1_neurons, layer2_neurons)\n",
    "        # self.layer3 = torch.nn.Linear(layer2_neurons, layer3_neurons)\n",
    "        # self.layer4 = torch.nn.Linear(layer3_neurons, layer4_neurons)\n",
    "        self.out = torch.nn.Linear(layer2_neurons, out_features)\n",
    "        ###################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the activation functions\n",
    "        \"\"\"\n",
    "        #######\tADD YOUR CODE HERE\t#######\n",
    "        x = torch.nn.functional.relu(self.layer1(x))\n",
    "        x = torch.nn.functional.relu(self.layer2(x))\n",
    "        # x = torch.nn.functional.relu(self.layer3(x))\n",
    "        # x = torch.nn.functional.relu(self.layer4(x))\n",
    "        x = self.out(x)\n",
    "        predicted_output = x\n",
    "        ###################################\n",
    "\n",
    "        return predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Salary_Predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss_function():\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    To define the loss function for the model. Loss function measures\n",
    "    how well the predictions of a model match the actual target values\n",
    "    in training data.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `loss_function`: This can be a pre-defined loss function in PyTorch\n",
    "                                    or can be user-defined\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    loss_function = model_loss_function()\n",
    "    \"\"\"\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    ##########################################################\n",
    "\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimizer(model):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    To define the optimizer for the model. Optimizer is responsible\n",
    "    for updating the parameters (weights and biases) in a way that\n",
    "    minimizes the loss function.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    `model`: An object of the 'Salary_Predictor' class\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `optimizer`: Pre-defined optimizer from Pytorch\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    optimizer = model_optimizer(model)\n",
    "    \"\"\"\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    ##########################################################\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Salary_Predictor()\n",
    "# model_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_number_of_epochs():\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    To define the number of epochs for training the model\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `number_of_epochs`: [integer value]\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    number_of_epochs = model_number_of_epochs()\n",
    "    \"\"\"\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    number_of_epochs = 1000\n",
    "    ##########################################################\n",
    "\n",
    "    return number_of_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(\n",
    "    model,\n",
    "    number_of_epochs,\n",
    "    tensors_and_iterable_training_data,\n",
    "    loss_function,\n",
    "    optimizer,\n",
    "):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    All the required parameters for training are passed to this function.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    1. `model`: An object of the 'Salary_Predictor' class\n",
    "    2. `number_of_epochs`: For training the model\n",
    "    3. `tensors_and_iterable_training_data`: list containing training and validation data tensors\n",
    "                                                                                     and iterable dataset object of training tensors\n",
    "    4. `loss_function`: Loss function defined for the model\n",
    "    5. `optimizer`: Optimizer defined for the model\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    trained_model\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    trained_model = training_function(model, number_of_epochs, iterable_training_data, loss_function, optimizer)\n",
    "\n",
    "    \"\"\"\n",
    "    #################\tADD YOUR CODE HERE\t##################\n",
    "    X_train = tensors_and_iterable_training_data[0]\n",
    "    Y_train = tensors_and_iterable_training_data[2]\n",
    "    losses = []\n",
    "    for i in range(number_of_epochs):\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = loss_function(y_pred, Y_train)\n",
    "        losses.append(loss.detach().numpy())\n",
    "\n",
    "        # print every 10 epoch\n",
    "        # if i % 10 == 0:\n",
    "        #     print(f\"Epoch: {i} and loss: {loss}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # plt.plot(range(number_of_epochs), losses)\n",
    "    # plt.ylabel(\"loss/error\")\n",
    "    # plt.xlabel(\"Epoch\")\n",
    "    # trained_model = torch.save(model.forward, \"/mnt/Storage Drive/Projects/E-YRC/EYRC_2023/Task 1/Task_1A/model.pt\")\n",
    "    trained_model = model\n",
    "    ##########################################################\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Salary_Predictor()\n",
    "# training_function(\n",
    "#     model, model_number_of_epochs(), load_as_tensors(identify_features_and_targets(\n",
    "#         data_preprocessing(dataframe_path))), model_loss_function(), model_optimizer(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
    "    '''\n",
    "    Purpose:\n",
    "    ---\n",
    "    This function will utilise the trained model to do predictions on the\n",
    "    validation dataset. This will enable us to understand the accuracy of\n",
    "    the model.\n",
    "\n",
    "    Input Arguments:\n",
    "    ---\n",
    "    1. `trained_model`: Returned from the training function\n",
    "    2. `tensors_and_iterable_training_data`: list containing training and validation data tensors \n",
    "                                                                                     and iterable dataset object of training tensors\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    model_accuracy: Accuracy on the validation dataset\n",
    "\n",
    "    Example call:\n",
    "    ---\n",
    "    model_accuracy = validation_function(trained_model, tensors_and_iterable_training_data)\n",
    "\n",
    "    '''\n",
    "    #################\tADD YOUR CODE HERE\t##################  \n",
    "    X_test = tensors_and_iterable_training_data[1]\n",
    "    Y_test = tensors_and_iterable_training_data[3]\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    trained_model.eval()\n",
    "    with torch.no_grad():  # Basically turn off back propogation    \n",
    "        y_eval = trained_model.forward(X_test) # X_test are features from our test set, y_eval will be predictions\n",
    "        loss = loss_function(y_eval, Y_test) # Find the loss or error\n",
    "    model_accuracy = 100-loss\n",
    "    ##########################################################\n",
    "\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1763076520.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import torch from torch.autograd\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch from torch.autograd\n",
    "import grad x = torch.ones(2, 2, requires_grad=True)\n",
    "v = x + 2\n",
    "y = v ** 2\n",
    "dy_hat_dx = grad(outputs=y, inputs=x)\n",
    "print(dy_hat_dx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_function(model, load_as_tensors(identify_features_and_targets(data_preprocessing(dataframe_path))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### YOU ARE NOT ALLOWED TO MAKE CHANGES TO THIS FUNCTION #########\t\n",
    "\n",
    "\n",
    "'''\n",
    "\tPurpose:\n",
    "\t---\n",
    "\tThe following is the main function combining all the functions\n",
    "\tmentioned above. Go through this function to understand the flow\n",
    "\tof the script\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set = 99.4454574584961\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "########################################################################\n",
    "######### YOU ARE NOT ALLOWED TO MAKE CHANGES TO THIS FUNCTION #########\n",
    "\"\"\"\n",
    "\tPurpose:\n",
    "\t---\n",
    "\tThe following is the main function combining all the functions\n",
    "\tmentioned above. Go through this function to understand the flow\n",
    "\tof the script\n",
    "\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    # reading the provided dataset csv file using pandas library and\n",
    "    # converting it to a pandas Dataframe\n",
    "    dataframe_path = (\n",
    "        \"/mnt/Storage Drive/Projects/E-YRC/EYRC_2023/Task 1/Task_1A/task_1a_dataset.csv\"\n",
    "    )\n",
    "    task_1a_dataframe = pandas.read_csv(dataframe_path)\n",
    "    # data preprocessing and obtaining encoded data\n",
    "    encoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
    "    # selecting required features and targets\n",
    "    features_and_targets = identify_features_and_targets(encoded_dataframe)\n",
    "\n",
    "    # obtaining training and validation data tensors and the iterable\n",
    "    # training data object\n",
    "    tensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
    "\n",
    "    # model is an instance of the class that defines the architecture of the model\n",
    "    model = Salary_Predictor()\n",
    "\n",
    "    # obtaining loss function, optimizer and the number of training epochs\n",
    "    loss_function = model_loss_function()\n",
    "    optimizer = model_optimizer(model)\n",
    "    number_of_epochs = model_number_of_epochs()\n",
    "\n",
    "    # training the model\n",
    "    trained_model = training_function(\n",
    "        model,\n",
    "        number_of_epochs,\n",
    "        tensors_and_iterable_training_data,\n",
    "        loss_function,\n",
    "        optimizer,\n",
    "    )\n",
    "\n",
    "    # validating and obtaining accuracy\n",
    "    model_accuracy = validation_function(\n",
    "        trained_model, tensors_and_iterable_training_data\n",
    "    )\n",
    "    print(f\"Accuracy on the test set = {model_accuracy}\")\n",
    "\n",
    "    X_train_tensor = tensors_and_iterable_training_data[0]\n",
    "    x = X_train_tensor[0]\n",
    "    jitted_model = torch.jit.save(\n",
    "        torch.jit.trace(model, (x)), \"task_1a_trained_model.pth\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORT MODULES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 18:05:21.774670: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-02 18:05:21.815408: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-02 18:05:21.815456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-02 18:05:21.816630: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-02 18:05:21.822649: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-02 18:05:21.823436: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-02 18:05:22.641078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/srikar/miniconda3/envs/GG_1240/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    \"combat\",\n",
    "    \"destroyed_buildings\",\n",
    "    \"fire\",\n",
    "    \"human_aid_rehabilitation\",\n",
    "    \"military_vehicles\",\n",
    "]\n",
    "IMG_SIZE = (90, 90)\n",
    "IMAGE_ORDER = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "predicted_class_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input and preprocess the Arena Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_arena(arena):\n",
    "    arena = cv.rotate(arena, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    arena = arena[450:1750, 0:1080]\n",
    "    return arena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aruco Markers detection for ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ArUco_details(image):\n",
    "    ArUco_details_dict = {}\n",
    "    ArUco_corners = {}\n",
    "\n",
    "    ##############\tADD YOUR CODE HERE\t##############\n",
    "    # image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # image_gray = cv.GaussianBlur(image_gray, (3, 3), 1)\n",
    "    # dictionary = aruco.Dictionary_get(cv.aruco.DICT_4X4_1000)\n",
    "    # parameters = aruco.DetectorParameters_create()\n",
    "    # # detector = aruco.detectMarkers(image_gray, dictionary, parameters)\n",
    "    # bboxs, ids, _ = aruco.detectMarkers(image_gray, dictionary, parameters=parameters)\n",
    "\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    # image_gray = cv.GaussianBlur(image_gray, (5, 5), 3)\n",
    "    dictionary = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_1000)\n",
    "    parameters = cv.aruco.DetectorParameters()\n",
    "    detector = cv.aruco.ArucoDetector(dictionary, parameters)\n",
    "    bboxs, ids, _ = detector.detectMarkers(image_gray)\n",
    "\n",
    "    # image = cv.flip(image, 1)\n",
    "\n",
    "    if ids is not None:\n",
    "        # bboxs[0][0][3],bboxs[0][0][2] = bboxs[0][0][2],bboxs[0][0][3]\n",
    "        # for i in range(0, 3):\n",
    "        #     bboxs[0][0][i][0] = abs(bboxs[0][0][i][0] - frame_width)\n",
    "        ArUco_corners2 = (np.int0(bboxs)).ravel()\n",
    "        # print(bboxs[0][0][0][0])\n",
    "        ArUco_corners = {}\n",
    "        ArUco_corners_list = []\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for i in range(0, len(ArUco_corners2), +2):\n",
    "            temp = []\n",
    "            temp.append(ArUco_corners2[i])\n",
    "            temp.append(ArUco_corners2[i + 1])\n",
    "            count1 += 1\n",
    "            ArUco_corners_list.append(temp)\n",
    "            if count1 % 4 == 0 and count1 != 0:\n",
    "                ArUco_corners[count2] = ArUco_corners_list\n",
    "                count2 += 1\n",
    "                ArUco_corners_list = []\n",
    "        ArUco_ID = ids.ravel()\n",
    "        centre = []\n",
    "        for i in range(0, len(ArUco_corners)):\n",
    "            sumx = 0\n",
    "            sumy = 0\n",
    "            for j in range(0, 4):\n",
    "                sumx += ArUco_corners[i][j][0]\n",
    "                sumy += ArUco_corners[i][j][1]\n",
    "            lst = []\n",
    "            lst.append(int(sumx / 4.0))\n",
    "            lst.append(int(sumy / 4.0))\n",
    "            centre.append(lst)\n",
    "\n",
    "        slope = []\n",
    "        for i in range(0, len(ArUco_corners)):\n",
    "            vr = 0\n",
    "            x1 = int(round((ArUco_corners[i][0][0] + ArUco_corners[i][1][0]) / 2))\n",
    "            y1 = int(round((ArUco_corners[i][0][1] + ArUco_corners[i][1][1]) / 2))\n",
    "            x2 = centre[i][0]\n",
    "            y2 = centre[i][1]\n",
    "            c = 0\n",
    "            if x2 == x1 and y2 <= y1:  # 2nd Quadrant\n",
    "                vr = -180\n",
    "                c += 1\n",
    "            elif x2 <= x1 and y2 == y1:  # 1st Quadrant\n",
    "                vr = -90\n",
    "                c += 1\n",
    "            elif x2 >= x1 and y2 == y1:  # 3rd Quadrant\n",
    "                vr = 90\n",
    "                c += 1\n",
    "            elif x2 == x1 and y2 >= y1:  # 4th Quadrant\n",
    "                vr = 0\n",
    "                c += 1\n",
    "            if c == 0:\n",
    "                x1 = ArUco_corners[i][0][0]\n",
    "                x2 = ArUco_corners[i][1][0]\n",
    "                y1 = ArUco_corners[i][0][1]\n",
    "                y2 = ArUco_corners[i][1][1]\n",
    "                if x1 != x2:\n",
    "                    vr = int(round(math.degrees(math.atan2((y1 - y2), (x2 - x1)))))\n",
    "                vr = int(vr)\n",
    "                x1 = int(round((ArUco_corners[i][0][0] + ArUco_corners[i][1][0]) / 2))\n",
    "                y1 = int(round((ArUco_corners[i][0][1] + ArUco_corners[i][1][1]) / 2))\n",
    "                x2 = centre[i][0]\n",
    "                y2 = centre[i][1]\n",
    "            slope.append(vr)\n",
    "        lst = []\n",
    "        for i in range(0, len(ArUco_ID)):\n",
    "            lst.append(centre[i])\n",
    "            lst.append(int(slope[i]))\n",
    "            ArUco_details_dict[int(ArUco_ID[i])] = lst\n",
    "            lst = []\n",
    "        ArUco_corners_copy = ArUco_corners.copy()\n",
    "        ArUco_corners = {}\n",
    "        for i in range(0, len(ArUco_ID)):\n",
    "            ArUco_corners[int(abs(ArUco_ID[i]))] = ArUco_corners_copy[i]\n",
    "\n",
    "    return ArUco_details_dict, ArUco_corners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI array creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ROI_Images(arena):\n",
    "    roi_images_array = []\n",
    "    event_arcs = [21, 29, 30, 34, 48]\n",
    "    for i in event_arcs:\n",
    "        ArUco_details_dict, _ = detect_ArUco_details(arena)\n",
    "        print(\"ArUco_details_dict\", ArUco_details_dict)\n",
    "        point1 = (ArUco_details_dict[i][0][0], ArUco_details_dict[i][0][1] - 50)\n",
    "        point2 = (\n",
    "            ArUco_details_dict[i][0][0] - 200,\n",
    "            ArUco_details_dict[i][0][1] + 120,\n",
    "        )\n",
    "        top_left = (min(point1[0], point2[0]), min(point1[1], point2[1]))\n",
    "        bottom_right = (max(point1[0], point2[0]), max(point1[1], point2[1]))\n",
    "        roi = arena[top_left[1] : bottom_right[1], top_left[0] : bottom_right[0]]\n",
    "\n",
    "        # roi_images = np.zeros_like(arena)\n",
    "        # roi_images[top_left[1] : bottom_right[1], top_left[0] : bottom_right[0]] = roi\n",
    "        # roi_images_array.append(roi_images)\n",
    "        roi_images_array.append(roi)\n",
    "    return roi_images_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply threshold sweep for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_sweep(roi_image):\n",
    "    flag = 0\n",
    "    block_size = 11\n",
    "    roi_image_gray = cv.GaussianBlur(roi_image, (3, 3), 1)\n",
    "    roi_image_gray = cv.cvtColor(roi_image_gray, cv.COLOR_BGR2GRAY)\n",
    "    # ret, thresh = cv.threshold(roi_image_gray, l_thresh, 256, cv.THRESH_BINARY)\n",
    "    thresh = cv.adaptiveThreshold(\n",
    "        roi_image_gray,\n",
    "        255,\n",
    "        cv.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv.THRESH_BINARY_INV,\n",
    "        block_size,\n",
    "        -2,\n",
    "    )\n",
    "    event_corners = []\n",
    "    contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        approx = cv.approxPolyDP(cnt, 0.1 * cv.arcLength(cnt, True), True)\n",
    "        # print(\"approx\", approx[0])\n",
    "        if len(approx) == 4:\n",
    "            x1, y1, w, h = cv.boundingRect(cnt)\n",
    "            ratio = float(w) / h\n",
    "            area = w * h\n",
    "            if ratio >= 0.9 and ratio <= 1.2 and area > 7000 and area < 9800:\n",
    "                \n",
    "                for i in range(0, 4):\n",
    "                    event_corners.append(approx[i][0])\n",
    "                # flag = 1\n",
    "                # thresh = cv.rectangle(\n",
    "                #     thresh, approx[1][0], approx[3][0], (0, 255, 0), 3\n",
    "                # )\n",
    "    #             break\n",
    "    # if flag == 1:\n",
    "    #     break\n",
    "\n",
    "    return thresh, event_corners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the bounding square on the original Arena Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_bounding_square(arena, event_corners):\n",
    "    pts = np.reshape(event_corners, (-1, 1, 2))\n",
    "    print(\"pts\", pts)\n",
    "    # min = pts[0]\n",
    "    # for i in range(1, 4):\n",
    "    #     if min[0][0] < pts[i][0][0] and min[0][1] < pts[i][0][1]:\n",
    "    #         min = pts[i]\n",
    "    #     # if max[0][0] > pts[i][0][0] and max[0][1] > pts[i][0][1]:\n",
    "    #     #     max = pts[i]\n",
    "    # new_pts = []\n",
    "    # for j in range(0, i):\n",
    "    #     new_pts[j] = pts[i-j - 1]\n",
    "    # points = pts.copy()\n",
    "    # points = sorted(points, key=lambda point: point[0])\n",
    "    \n",
    "    # # Separate points into left and right\n",
    "    # left_points = sorted(points[:2], key=lambda point: point[1])\n",
    "    # right_points = sorted(points[2:], key=lambda point: point[1])\n",
    "\n",
    "\n",
    "    # new_pts = np.reshape(\n",
    "    #     [left_points[0], left_points[1], right_points[1], right_points[0]], (-1, 1, 2)\n",
    "    # )\n",
    "    # print(\"new pts =\", new_pts)\n",
    "\n",
    "    width =  200\n",
    "    height = 200\n",
    "    dstPts = [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "    # print(\"intersect_pts\", pts)\n",
    "    matrix = cv.getPerspectiveTransform(np.float32(pts), np.float32(dstPts))\n",
    "    cropped_event = cv.warpPerspective(arena, matrix, (int(width), int(height)))\n",
    "    arena = cv.polylines(arena, [pts], 1, (0, 255, 0), 3)\n",
    "\n",
    "    return arena, cropped_event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(img_path):\n",
    "    loaded_model = load_model(\"/mnt/Storage/Dataset/mode1.h5\")\n",
    "    # print(loaded_model.summary())\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    probabilities = loaded_model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(probabilities)\n",
    "    pred = class_labels[predicted_class_index]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_name(arena, event, event_corners):\n",
    "    print(\"event_corners[0]\", event_corners[0])\n",
    "    arena = cv.putText(\n",
    "        arena,\n",
    "        event,\n",
    "        (\n",
    "            event_corners[3][0],\n",
    "            event_corners[3][1]+50,\n",
    "        ),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=1,\n",
    "        color=(0, 255, 0),\n",
    "        thickness=3,\n",
    "    )\n",
    "    return arena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each ROI (Main Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11573/1883346905.py:26: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  ArUco_corners2 = (np.int0(bboxs)).ravel()\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArUco_details_dict {6: [[1038, 1059], 0], 21: [[354, 978], 0], 20: [[443, 970], 0], 19: [[546, 964], 0], 18: [[653, 958], 4], 17: [[766, 953], 0], 23: [[60, 950], 0], 16: [[858, 949], 0], 15: [[968, 939], 0], 24: [[64, 879], 0], 14: [[992, 859], 4], 22: [[62, 813], 0], 25: [[202, 787], 0], 26: [[319, 774], 2], 27: [[438, 762], 0], 29: [[860, 749], 0], 11: [[985, 637], 0], 49: [[45, 584], 2], 9: [[978, 576], 0], 30: [[845, 556], 0], 31: [[668, 554], 0], 34: [[341, 553], 2], 12: [[978, 510], 0], 8: [[980, 440], 0], 36: [[846, 409], 0], 37: [[774, 407], 0], 38: [[691, 404], 0], 35: [[603, 402], 0], 39: [[432, 400], 0], 40: [[352, 394], 0], 42: [[173, 389], 0], 51: [[48, 342], 0], 10: [[979, 316], 0], 43: [[808, 247], 0], 44: [[729, 238], -2], 45: [[630, 234], 0], 46: [[532, 228], 0], 47: [[437, 226], 0], 48: [[355, 225], 0], 52: [[45, 224], 0], 53: [[82, 134], 0], 54: [[183, 113], 0], 4: [[1027, 78], -2]}\n",
      "ArUco_details_dict {6: [[1038, 1059], 0], 21: [[354, 978], 0], 20: [[443, 970], 0], 19: [[546, 964], 0], 18: [[653, 958], 4], 17: [[766, 953], 0], 23: [[60, 950], 0], 16: [[858, 949], 0], 15: [[968, 939], 0], 24: [[64, 879], 0], 14: [[992, 859], 4], 22: [[62, 813], 0], 25: [[202, 787], 0], 26: [[319, 774], 2], 27: [[438, 762], 0], 29: [[860, 749], 0], 11: [[985, 637], 0], 49: [[45, 584], 2], 9: [[978, 576], 0], 30: [[845, 556], 0], 31: [[668, 554], 0], 34: [[341, 553], 2], 12: [[978, 510], 0], 8: [[980, 440], 0], 36: [[846, 409], 0], 37: [[774, 407], 0], 38: [[691, 404], 0], 35: [[603, 402], 0], 39: [[432, 400], 0], 40: [[352, 394], 0], 42: [[173, 389], 0], 51: [[48, 342], 0], 10: [[979, 316], 0], 43: [[808, 247], 0], 44: [[729, 238], -2], 45: [[630, 234], 0], 46: [[532, 228], 0], 47: [[437, 226], 0], 48: [[355, 225], 0], 52: [[45, 224], 0], 53: [[82, 134], 0], 54: [[183, 113], 0], 4: [[1027, 78], -2]}\n",
      "ArUco_details_dict {6: [[1038, 1059], 0], 21: [[354, 978], 0], 20: [[443, 970], 0], 19: [[546, 964], 0], 18: [[653, 958], 4], 17: [[766, 953], 0], 23: [[60, 950], 0], 16: [[858, 949], 0], 15: [[968, 939], 0], 24: [[64, 879], 0], 14: [[992, 859], 4], 22: [[62, 813], 0], 25: [[202, 787], 0], 26: [[319, 774], 2], 27: [[438, 762], 0], 29: [[860, 749], 0], 11: [[985, 637], 0], 49: [[45, 584], 2], 9: [[978, 576], 0], 30: [[845, 556], 0], 31: [[668, 554], 0], 34: [[341, 553], 2], 12: [[978, 510], 0], 8: [[980, 440], 0], 36: [[846, 409], 0], 37: [[774, 407], 0], 38: [[691, 404], 0], 35: [[603, 402], 0], 39: [[432, 400], 0], 40: [[352, 394], 0], 42: [[173, 389], 0], 51: [[48, 342], 0], 10: [[979, 316], 0], 43: [[808, 247], 0], 44: [[729, 238], -2], 45: [[630, 234], 0], 46: [[532, 228], 0], 47: [[437, 226], 0], 48: [[355, 225], 0], 52: [[45, 224], 0], 53: [[82, 134], 0], 54: [[183, 113], 0], 4: [[1027, 78], -2]}\n",
      "ArUco_details_dict {6: [[1038, 1059], 0], 21: [[354, 978], 0], 20: [[443, 970], 0], 19: [[546, 964], 0], 18: [[653, 958], 4], 17: [[766, 953], 0], 23: [[60, 950], 0], 16: [[858, 949], 0], 15: [[968, 939], 0], 24: [[64, 879], 0], 14: [[992, 859], 4], 22: [[62, 813], 0], 25: [[202, 787], 0], 26: [[319, 774], 2], 27: [[438, 762], 0], 29: [[860, 749], 0], 11: [[985, 637], 0], 49: [[45, 584], 2], 9: [[978, 576], 0], 30: [[845, 556], 0], 31: [[668, 554], 0], 34: [[341, 553], 2], 12: [[978, 510], 0], 8: [[980, 440], 0], 36: [[846, 409], 0], 37: [[774, 407], 0], 38: [[691, 404], 0], 35: [[603, 402], 0], 39: [[432, 400], 0], 40: [[352, 394], 0], 42: [[173, 389], 0], 51: [[48, 342], 0], 10: [[979, 316], 0], 43: [[808, 247], 0], 44: [[729, 238], -2], 45: [[630, 234], 0], 46: [[532, 228], 0], 47: [[437, 226], 0], 48: [[355, 225], 0], 52: [[45, 224], 0], 53: [[82, 134], 0], 54: [[183, 113], 0], 4: [[1027, 78], -2]}\n",
      "ArUco_details_dict {6: [[1038, 1059], 0], 21: [[354, 978], 0], 20: [[443, 970], 0], 19: [[546, 964], 0], 18: [[653, 958], 4], 17: [[766, 953], 0], 23: [[60, 950], 0], 16: [[858, 949], 0], 15: [[968, 939], 0], 24: [[64, 879], 0], 14: [[992, 859], 4], 22: [[62, 813], 0], 25: [[202, 787], 0], 26: [[319, 774], 2], 27: [[438, 762], 0], 29: [[860, 749], 0], 11: [[985, 637], 0], 49: [[45, 584], 2], 9: [[978, 576], 0], 30: [[845, 556], 0], 31: [[668, 554], 0], 34: [[341, 553], 2], 12: [[978, 510], 0], 8: [[980, 440], 0], 36: [[846, 409], 0], 37: [[774, 407], 0], 38: [[691, 404], 0], 35: [[603, 402], 0], 39: [[432, 400], 0], 40: [[352, 394], 0], 42: [[173, 389], 0], 51: [[48, 342], 0], 10: [[979, 316], 0], 43: [[808, 247], 0], 44: [[729, 238], -2], 45: [[630, 234], 0], 46: [[532, 228], 0], 47: [[437, 226], 0], 48: [[355, 225], 0], 52: [[45, 224], 0], 53: [[82, 134], 0], 54: [[183, 113], 0], 4: [[1027, 78], -2]}\n",
      "pts [[[ 68  54]]\n",
      "\n",
      " [[ 70 140]]\n",
      "\n",
      " [[159 136]]\n",
      "\n",
      " [[156  50]]]\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "event_corners[0] [68 54]\n",
      "pts [[[134  57]]\n",
      "\n",
      " [[ 50  59]]\n",
      "\n",
      " [[ 50 144]]\n",
      "\n",
      " [[134 141]]]\n",
      "1/1 [==============================] - 1s 686ms/step\n",
      "event_corners[0] [134  57]\n",
      "pts [[[153  43]]\n",
      "\n",
      " [[ 70  44]]\n",
      "\n",
      " [[ 70 129]]\n",
      "\n",
      " [[154 127]]]\n",
      "1/1 [==============================] - 1s 681ms/step\n",
      "event_corners[0] [153  43]\n",
      "pts [[[148  55]]\n",
      "\n",
      " [[ 57  55]]\n",
      "\n",
      " [[ 59 142]]\n",
      "\n",
      " [[148 141]]]\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "event_corners[0] [148  55]\n",
      "pts [[[ 59  33]]\n",
      "\n",
      " [[ 59 121]]\n",
      "\n",
      " [[149 121]]\n",
      "\n",
      " [[148  34]]]\n"
     ]
    }
   ],
   "source": [
    "# arena = cv.imread(\"/mnt/Storage/Pictures/picture_2023-12-23_23-59-36 (copy).jpg\")\n",
    "try:\n",
    "    cap = cv.VideoCapture(\"/dev/video2\")\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open /dev/video2\")\n",
    "        raise Exception(\"Could not open /dev/video2\")\n",
    "except:\n",
    "    cap = cv.VideoCapture(\"/dev/video3\")\n",
    "    if not cap.isOpened():\n",
    "        print(\"Could not open /dev/video3 either. Please check your device.\")\n",
    "        try:\n",
    "            cap = cv.VideoCapture(\"/dev/video0\")\n",
    "            if not cap.isOpened():\n",
    "                print(\"Could not open /dev/video0\")\n",
    "                raise Exception(\"Could not open /dev/video0\")\n",
    "        except:\n",
    "            cap = cv.VideoCapture(\"/dev/video1\")\n",
    "            if not cap.isOpened():\n",
    "                print(\"Could not open /dev/video1 either. Please check your device.\")\n",
    "\n",
    "desired_width = 1920\n",
    "desired_height = 1080\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "ret, arena = cap.read()\n",
    "if detect_ArUco_details(arena) == {}:\n",
    "    try:\n",
    "        cap = cv.VideoCapture(\"/dev/video0\")\n",
    "        if not cap.isOpened():\n",
    "            print(\"Could not open /dev/video0\")\n",
    "            raise Exception(\"Could not open /dev/video0\")\n",
    "    except:\n",
    "        cap = cv.VideoCapture(\"/dev/video1\")\n",
    "        if not cap.isOpened():\n",
    "            print(\"Could not open /dev/video1 either. Please check your device.\")\n",
    "    desired_width = 1920\n",
    "    desired_height = 1080\n",
    "    cap.set(cv.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    cap.set(cv.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "\n",
    "arena = preprocess_arena(arena)\n",
    "cv.imshow(\"I_Arena\", arena)\n",
    "\n",
    "\n",
    "roi_images = get_ROI_Images(arena)\n",
    "for i in range(0, 5):\n",
    "    cv.imwrite(\"ROI1\" + str(i) + \".jpg\", roi_images[i])\n",
    "    thresh, event_corners = threshold_sweep(roi_images[i])\n",
    "    # cv.imshow(\"thresh_images\" + str(i), thresh)\n",
    "    # print(\"Event Corners at \" + str(i) + \" is \", event_corners)\n",
    "    if len(event_corners) != 0:\n",
    "        arena, cropped_event = put_bounding_square(arena, event_corners)\n",
    "        if i != 4:\n",
    "            cropped_event = cv.rotate(cropped_event, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cropped_event = cv.flip(cropped_event, 1)\n",
    "        cropped_image_path = (\n",
    "            \"/mnt/Storage/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/Live_Images/Img_\"\n",
    "            + str(i)\n",
    "            + \".jpg\"\n",
    "        )\n",
    "        cv.imwrite(cropped_image_path, cropped_event)\n",
    "        cv.imshow(\"cropped_images\" + str(i), cropped_event)\n",
    "        event = predict_class(cropped_image_path)\n",
    "        arena = add_event_name(arena, event, event_corners)\n",
    "\n",
    "\n",
    "while 1:\n",
    "    arena = cv.resize(arena, (1000, 800))\n",
    "    cv.imshow(\"Arena\", arena)\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_1240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

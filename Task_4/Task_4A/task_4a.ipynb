{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORT MODULES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 19:01:30.721695: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-28 19:01:30.785295: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 19:01:30.785337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 19:01:30.786536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 19:01:30.794892: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-28 19:01:30.795336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 19:01:32.295854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/srikar/miniconda3/envs/GG_1240/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    \"combat\",\n",
    "    \"destroyed_buildings\",\n",
    "    \"fire\",\n",
    "    \"human_aid_rehabilitation\",\n",
    "    \"military_vehicles\",\n",
    "]\n",
    "IMG_SIZE = (90, 90)\n",
    "IMAGE_ORDER = [\"C\", \"B\", \"E\", \"D\", \"A\"]\n",
    "predicted_class_list = {}\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(IMG_SIZE),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(img_path):\n",
    "    loaded_model = load_model(\"/mnt/Storage/Dataset/model.h5\")\n",
    "    # print(loaded_model.summary())\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    probabilities = loaded_model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(probabilities)\n",
    "    pred = class_labels[predicted_class_index]\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "fire\n"
     ]
    }
   ],
   "source": [
    "print(predict_class(\"/mnt/Storage/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/ROI2.jpg\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code flow**\n",
    "1. Input and preprocess the Arena Image (crop, rotation, distortion constant and camera matrix).\n",
    "2. Gray Scale of the Image.\n",
    "3. Aruco Markers detection for ROI.\n",
    "4. ROI array creation.\n",
    "5. Loop through each ROI.\n",
    "6. Apply threshold sweep for each ROI.\n",
    "7. Get the bounding square on the original Arena Image.\n",
    "8. Flatten to a square image.\n",
    "9. Add a bounding rectangle on the arena image.\n",
    "10. Feed the square image into the model.\n",
    "11. Add the name of the class on the arena Image.\n",
    "12. Display the final image for 20 seconds after looping through each ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rectangle(frame, event_list, image_cnts, frame_count):\n",
    "    # cv.imwrite(\"/mnt/Storage Drive/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/add_rectangle_and_name.jpg\",frame)\n",
    "    # frame = cv.rotate(frame, cv.ROTATE_90_CLOCKWISE)\n",
    "    for i in range(0, image_cnts):\n",
    "        pts = np.reshape(event_list[i], (-1, 1, 2))\n",
    "        # print(\"pts\", event_list[i])\n",
    "        width = 150\n",
    "        height = 150\n",
    "        dstPts = [[0, 0], [width, 0], [width, height], [0, height]]\n",
    "        # print(\"intersect_pts\", pts)\n",
    "        # Get the transform\n",
    "        matrix = cv.getPerspectiveTransform(np.float32(pts), np.float32(dstPts))\n",
    "        # Transform the image\n",
    "        out = cv.warpPerspective(frame, matrix, (int(width), int(height)))\n",
    "        # out = cv.flip(out, 1)\n",
    "        out = cv.rotate(out, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        image = cv.polylines(frame, [pts], 1, (0, 255, 0), 3)\n",
    "        predicted_class = \"\"\n",
    "        if frame_count < 1:\n",
    "            image_path = (\n",
    "                \"/mnt/Storage/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/Live_Images/Img_\"\n",
    "                + str(i)\n",
    "                + \".jpg\"\n",
    "            )\n",
    "            # if(image_cnts == 4):\n",
    "            # out = cv.rotate(out, cv.ROTATE_90_CLOCKWISE)\n",
    "            cv.imwrite(image_path, out)\n",
    "            predicted_class = predict_class(image_path)\n",
    "            print(\"predicted_class\", predicted_class)\n",
    "            predicted_class_list[IMAGE_ORDER[i]] = predicted_class\n",
    "\n",
    "        # else:\n",
    "        #     predict_class = \"\"\n",
    "        # print(\"pts\",pts)\n",
    "        # print(\"pts\",pts[1][0][1]).\n",
    "    # text_image = np.zeros_like(image)\n",
    "    # cv.putText(\n",
    "    #     text_image,\n",
    "    #     predicted_class_list[i],\n",
    "    #     (pts[1][0][0] + 10, pts[1][0][1] + 50),\n",
    "    #     cv.FONT_HERSHEY_SIMPLEX,\n",
    "    #     thickness=3,\n",
    "    #     fontScale=1,\n",
    "    #     color=(0, 255, 0),\n",
    "    # )\n",
    "    # rotation_angle = -90  # degrees\n",
    "    # image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    # rotation_mat = cv.getRotationMatrix2D(image_center, rotation_angle, 1.)\n",
    "\n",
    "    # # Rotate the text image\n",
    "    # text_image_rotated = cv.warpAffine(text_image, rotation_mat, image.shape[1::-1], flags=cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
    "\n",
    "    # # Overlay the rotated text image onto the original image\n",
    "    # image = cv.add(image, text_image_rotated)\n",
    "\n",
    "    # image = cv.resize(image, ((1980 // 2) - 20, (1080) - 50))\n",
    "    # image = cv.resize(image, (1800,1000))\n",
    "    return image, predicted_class_list\n",
    "\n",
    "    # cv.imshow(\"Image\", image)\n",
    "    # print(\"Out\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_name(image, predicted_class_list, event_list,image_cnts):\n",
    "    image = cv.rotate(image, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    image = image[500:1750, 0:1080]\n",
    "    for i in range(0,image_cnts):\n",
    "        image = cv.putText(image, predicted_class_list[IMAGE_ORDER[i]],(event_list[i][0][1]+100,abs(image.shape[0]-event_list[i][0][0])+130),cv.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 255, 0), thickness=3)\n",
    "    image = cv.resize(image, (1000, 900))\n",
    "\n",
    "    cv.imshow(\"add_event_name\",image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_square_identification(arena):\n",
    "    # cv.imwrite(\"/mnt/Storage Drive/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/event_square_identification.jpg\",arena)\n",
    "    event_list = []\n",
    "    arena_org = arena.copy()\n",
    "    image_cnts = 0\n",
    "    border_width = 5\n",
    "    arena_gray = cv.cvtColor(arena, cv.COLOR_BGR2GRAY)\n",
    "    # cv.imshow(\"gray\", arena_gray)\n",
    "    arena_gray = cv.GaussianBlur(arena_gray, (3, 3), 1)\n",
    "    ret, thresh = cv.threshold(arena_gray, 150, 256, cv.THRESH_BINARY)\n",
    "    # cv.imshow(\"thresh\", thresh)\n",
    "    contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        approx = cv.approxPolyDP(cnt, 0.1 * cv.arcLength(cnt, True), True)\n",
    "        if len(approx) == 4:\n",
    "            x1, y1, w, h = cv.boundingRect(cnt)\n",
    "            ratio = float(w) / h\n",
    "            area = w * h\n",
    "            # print(\"approx\", approx[0])\n",
    "            if ratio >= 0.9 and ratio <= 1.2 and area > 7000 and area < 9800:\n",
    "                print(\"Area at \", image_cnts, \" is \", area)\n",
    "                image_cnts += 1\n",
    "                list = []\n",
    "                for i in range(0, 4):\n",
    "                    list.append(approx[i][0])\n",
    "                event_list.append(list)\n",
    "    return event_list, image_cnts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ArUco_details(image):\n",
    "    ArUco_details_dict = {}\n",
    "    ArUco_corners = {}\n",
    "\n",
    "    ##############\tADD YOUR CODE HERE\t##############\n",
    "    image_gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    image_gray = cv.GaussianBlur(image_gray, (3, 3), 1)\n",
    "    dictionary = cv.aruco.getPredefinedDictionary(cv.aruco.DICT_4X4_1000)\n",
    "    parameters = cv.aruco.DetectorParameters()\n",
    "    detector = cv.aruco.ArucoDetector(dictionary, parameters)\n",
    "    bboxs, ids, _ = detector.detectMarkers(image)\n",
    "    # image = cv2.flip(image, 1)\n",
    "\n",
    "    if ids is not None:\n",
    "        \n",
    "        ArUco_corners2 = (np.int0(bboxs)).ravel()\n",
    "        # print(bboxs[0][0][0][0])\n",
    "        ArUco_corners = {}\n",
    "        ArUco_corners_list = []\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        for i in range(0, len(ArUco_corners2), +2):\n",
    "            temp = []\n",
    "            temp.append(ArUco_corners2[i])\n",
    "            temp.append(ArUco_corners2[i + 1])\n",
    "            count1 += 1\n",
    "            ArUco_corners_list.append(temp)\n",
    "            if count1 % 4 == 0 and count1 != 0:\n",
    "                ArUco_corners[count2] = ArUco_corners_list\n",
    "                count2 += 1\n",
    "                ArUco_corners_list = []\n",
    "        ArUco_ID = ids.ravel()\n",
    "        centre = []\n",
    "        for i in range(0, len(ArUco_corners)):\n",
    "            sumx = 0\n",
    "            sumy = 0\n",
    "            for j in range(0, 4):\n",
    "                sumx += ArUco_corners[i][j][0]\n",
    "                sumy += ArUco_corners[i][j][1]\n",
    "            lst = []\n",
    "            lst.append(int(sumx / 4.0))\n",
    "            lst.append(int(sumy / 4.0))\n",
    "            centre.append(lst)\n",
    "\n",
    "        slope = []\n",
    "        for i in range(0, len(ArUco_corners)):\n",
    "            vr = 0\n",
    "            x1 = int(round((ArUco_corners[i][0][0] + ArUco_corners[i][1][0]) / 2))\n",
    "            y1 = int(round((ArUco_corners[i][0][1] + ArUco_corners[i][1][1]) / 2))\n",
    "            x2 = centre[i][0]\n",
    "            y2 = centre[i][1]\n",
    "            c = 0\n",
    "            if x2 == x1 and y2 <= y1:  # 2nd Quadrant\n",
    "                vr = -180\n",
    "                c += 1\n",
    "            elif x2 <= x1 and y2 == y1:  # 1st Quadrant\n",
    "                vr = -90\n",
    "                c += 1\n",
    "            elif x2 >= x1 and y2 == y1:  # 3rd Quadrant\n",
    "                vr = 90\n",
    "                c += 1\n",
    "            elif x2 == x1 and y2 >= y1:  # 4th Quadrant\n",
    "                vr = 0\n",
    "                c += 1\n",
    "            if c == 0:\n",
    "                x1 = ArUco_corners[i][0][0]\n",
    "                x2 = ArUco_corners[i][1][0]\n",
    "                y1 = ArUco_corners[i][0][1]\n",
    "                y2 = ArUco_corners[i][1][1]\n",
    "                if x1 != x2:\n",
    "                    vr = int(round(math.degrees(math.atan2((y1 - y2), (x2 - x1)))))\n",
    "                vr = int(vr)\n",
    "                x1 = int(round((ArUco_corners[i][0][0] + ArUco_corners[i][1][0]) / 2))\n",
    "                y1 = int(round((ArUco_corners[i][0][1] + ArUco_corners[i][1][1]) / 2))\n",
    "                x2 = centre[i][0]\n",
    "                y2 = centre[i][1]\n",
    "            slope.append(vr)\n",
    "        lst = []\n",
    "        for i in range(0, len(ArUco_ID)):\n",
    "            lst.append(centre[i])\n",
    "            lst.append(int(slope[i]))\n",
    "            ArUco_details_dict[int(ArUco_ID[i])] = lst\n",
    "            lst = []\n",
    "        ArUco_corners_copy = ArUco_corners.copy()\n",
    "        ArUco_corners = {}\n",
    "        for i in range(0, len(ArUco_ID)):\n",
    "            ArUco_corners[int(abs(ArUco_ID[i]))] = ArUco_corners_copy[i]\n",
    "\n",
    "    return ArUco_details_dict, ArUco_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(roi_image):\n",
    "    flag = 0\n",
    "    for l_thresh in range(100, 255):\n",
    "        # roi_image_gray = cv.GaussianBlur(roi_image, (3, 3), 1)\n",
    "        roi_image_gray = cv.cvtColor(roi_image_gray, cv.COLOR_BGR2GRAY)\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        arena_gray = cv.dilate(arena_gray, kernel, iterations=2)\n",
    "        arena_gray = cv.fastNlMeansDenoising(\n",
    "            src=arena_gray, dst=None, h=10, templateWindowSize=7, searchWindowSize=21\n",
    "        )\n",
    "        # ret, thresh = cv.threshold(roi_image_gray, l_thresh, 256, cv.THRESH_BINARY)\n",
    "        thresh = cv.adaptiveThreshold(\n",
    "            arena_gray, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY_INV, 11, -2\n",
    "        )\n",
    "\n",
    "        contours, hierarchy = cv.findContours(\n",
    "            thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        for cnt in contours:\n",
    "            approx = cv.approxPolyDP(cnt, 0.01 * cv.arcLength(cnt, True), True)\n",
    "            if len(approx) == 4:\n",
    "                x1, y1, w, h = cv.boundingRect(cnt)\n",
    "                ratio = float(w) / h\n",
    "                area = w * h\n",
    "                if ratio >= 0.9 and ratio <= 1.2 and area > 9600 and area < 12000:\n",
    "                    flag = 1\n",
    "        if flag == 1:\n",
    "            return l_thresh\n",
    "\n",
    "    if flag == 0:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_threshold(cv.imread(\"/mnt/Storage/Projects/E-YRC/EYRC_2023/Task_4/Task_4A/ROI_21.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_Images(arena_image):\n",
    "    roi_images_array = []\n",
    "    event_arcs = [21, 29, 30, 34, 48]\n",
    "    for i in event_arcs:\n",
    "        ArUco_details_dict, _ = detect_ArUco_details(arena_image)\n",
    "        if ArUco_details_dict[i][1] > -100 and ArUco_details_dict[i][1] < -80:\n",
    "            point1 = (ArUco_details_dict[i][0][0] + 50, ArUco_details_dict[i][0][1])\n",
    "            point2 = (\n",
    "                ArUco_details_dict[i][0][0] - 120,\n",
    "                ArUco_details_dict[i][0][1] - 200,\n",
    "            )\n",
    "            top_left = (min(point1[0], point2[0]), min(point1[1], point2[1]))\n",
    "            bottom_right = (max(point1[0], point2[0]), max(point1[1], point2[1]))\n",
    "            roi = arena_image[\n",
    "                top_left[1] : bottom_right[1], top_left[0] : bottom_right[0]\n",
    "            ]\n",
    "        elif ArUco_details_dict[i][1] < 10 and ArUco_details_dict[i][1] > -10:\n",
    "            roi = arena_image[\n",
    "                (ArUco_details_dict[i][0][0], ArUco_details_dict[i][0][1] - 50),\n",
    "                (ArUco_details_dict[i][0][0] - 200, ArUco_details_dict[i][0][1] + 120),\n",
    "            ]\n",
    "   \n",
    "        roi_images = np.zeros_like(arena_image)\n",
    "        roi_images[top_left[1] : bottom_right[1], top_left[0] : bottom_right[0]] = roi\n",
    "        roi_images_array.append(roi_images)\n",
    "    #     cv.imshow(\"roi_images\"+str(i), roi_images)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "# ROI_Images(\n",
    "#     cv.imread(\"/mnt/Storage Drive/Pictures/picture_2023-12-23_23-59-36 (copy).jpg\")\n",
    "# )\n",
    "    return roi_images_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_square_identification(arena_image):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def get_camera_index(camera_name):\n",
    "    # List all video devices\n",
    "    devices = (\n",
    "        subprocess.check_output([\"v4l2-ctl\", \"--list-devices\"])\n",
    "        .decode(\"utf-8\")\n",
    "        .split(\"\\n\\n\")\n",
    "    )\n",
    "\n",
    "    for device in devices:\n",
    "        if camera_name in device:\n",
    "            # Extract the video device index from the device string\n",
    "            video_device = device.split(\"\\n\")[1]\n",
    "            index = int(\n",
    "                video_device[-1]\n",
    "            )  # Assumes the device file is in the format /dev/videoX\n",
    "            return index\n",
    "\n",
    "    print(f\"Could not find a camera with the name {camera_name}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def connect_to_camera(camera_name):\n",
    "    camera_index = get_camera_index(camera_name)\n",
    "    if camera_index is None:\n",
    "        return None\n",
    "\n",
    "    # Connect to the camera\n",
    "    camera = cv.VideoCapture(camera_index)\n",
    "\n",
    "    if not camera.isOpened():\n",
    "        print(f\"Cannot open camera named {camera_name} at index {camera_index}\")\n",
    "        return None\n",
    "\n",
    "    return camera\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "cap = connect_to_camera(\n",
    "    \"Lenovo FHD Webcam\"\n",
    ")  # Change the name to connect to a different camera\n",
    "\n",
    "if cap is not None:\n",
    "    # Capture a single frame\n",
    "    ret, frame = cap.read()\n",
    "    while(1):\n",
    "        cv.imshow(\"frame\",frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_4a_return():\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    ---\n",
    "    Only for returning the final dictionary variable\n",
    "\n",
    "    Arguments:\n",
    "    ---\n",
    "    You are not allowed to define any input arguments for this function. You can\n",
    "    return the dictionary from a user-defined function and just call the\n",
    "    function here\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    `identified_labels` : { dictionary }\n",
    "        dictionary containing the labels of the events detected\n",
    "    \"\"\"\n",
    "    identified_labels = {}\n",
    "\n",
    "    ##############\tADD YOUR CODE HERE\t##############\n",
    "\n",
    "    # try:\n",
    "    #     cap = cv.VideoCapture(\"/dev/video2\")\n",
    "    #     if not cap.isOpened():\n",
    "    #         raise Exception(\"Could not open /dev/video2\")\n",
    "    # except:\n",
    "    #     cap = cv.VideoCapture(\"/dev/video3\")\n",
    "    #     if not cap.isOpened():\n",
    "    #         print(\"Could not open /dev/video3 either. Please check your device.\")\n",
    "    #         try:\n",
    "    #             cap = cv.VideoCapture(\"/dev/video0\")\n",
    "    #             if not cap.isOpened():\n",
    "    #                 raise Exception(\"Could not open /dev/video0\")\n",
    "    #         except:\n",
    "    #             cap = cv.VideoCapture(\"/dev/video1\")\n",
    "    #             if not cap.isOpened():\n",
    "    #                 print(\"Could not open /dev/video1 either. Please check your device.\")\n",
    "    # desired_width = 1920\n",
    "    # desired_height = 1080\n",
    "    # cap.set(cv.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    # cap.set(cv.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "    # _, f = cap.read()\n",
    "    # print(\"detect_ArUco_details\", detect_ArUco_details(f))\n",
    "    # if detect_ArUco_details(f) == ({}, {}):\n",
    "    #     cap.release()\n",
    "    #     try:\n",
    "    #         cap = cv.VideoCapture(\"/dev/video0\")\n",
    "    #         if not cap.isOpened():\n",
    "    #             print(\"Could not open /dev/video0\")\n",
    "    #             raise Exception(\"Could not open /dev/video0\")\n",
    "    #     except:\n",
    "    #         cap = cv.VideoCapture(\"/dev/video1\")\n",
    "    #         if not cap.isOpened():\n",
    "    #             print(\"Could not open /dev/video1 either. Please check your device.\")\n",
    "    #     desired_width = 1920\n",
    "    #     desired_height = 1080\n",
    "    #     cap.set(cv.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    #     cap.set(cv.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "    cap = connect_to_camera(\"Lenovo FHD Webcam\")\n",
    "    frame_count = 0\n",
    "    while 1:\n",
    "        # Capture the video frame\n",
    "        # by frame\n",
    "        ret, frame = cap.read()\n",
    "        cv.imshow(\"frme\", frame)\n",
    "        # frame = cv.rotate(frame.copy(), cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        event_list, image_cnts = event_square_identification(frame)\n",
    "\n",
    "        print(\"event_list\", event_list)\n",
    "        print(\"image_cnts\", image_cnts)\n",
    "        # frame = cv.rotate(frame.copy(), cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        image, predicted_class_list = add_rectangle(\n",
    "            frame, event_list, image_cnts, frame_count\n",
    "        )\n",
    "        add_event_name(image, predicted_class_list, event_list, image_cnts)\n",
    "        predicted_class_list = dict(\n",
    "            sorted(predicted_class_list.items(), key=lambda item: item[0])\n",
    "        )\n",
    "        print(\"predicted_class_list\", predicted_class_list)\n",
    "        image = cv.rotate(image, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        image = cv.resize(image, (1000, 1550))\n",
    "\n",
    "        cv.imshow(\"img\", image[400:1300, 20:980])\n",
    "        identified_labels = predicted_class_list\n",
    "        frame_count += 1\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    ##################################################\n",
    "    return identified_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     identified_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtask_4a_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(identified_labels)\n",
      "Cell \u001b[0;32mIn[19], line 67\u001b[0m, in \u001b[0;36mtask_4a_return\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrme\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# frame = cv.rotate(frame.copy(), cv.ROTATE_90_COUNTERCLOCKWISE)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m event_list, image_cnts \u001b[38;5;241m=\u001b[39m event_square_identification(frame)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, event_list)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_cnts\u001b[39m\u001b[38;5;124m\"\u001b[39m, image_cnts)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    identified_labels = task_4a_return()\n",
    "    print(identified_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_1240",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
